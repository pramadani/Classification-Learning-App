{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lw3zRTs15Ly-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JRegeyH5oUi",
        "outputId": "0fb940ca-3a9f-4a97-a2b6-d0662d5001f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2850 images belonging to 5 classes.\n",
            "Found 2850 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "base_dir = 'images/split/training'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.5\n",
        ")\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    color_mode='grayscale',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = data_gen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    color_mode='grayscale',\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "JzinM2r85pz6"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(512, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    # Dropout(0.5),\n",
        "    Dense(5, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "2wXkMulq5wVy"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.callbacks import Callback\n",
        "\n",
        "class BaselineEarlyStopping(EarlyStopping):\n",
        "    def __init__(self, baseline, **kwargs):\n",
        "        super(BaselineEarlyStopping, self).__init__(**kwargs)\n",
        "        self.baseline = baseline\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return\n",
        "\n",
        "        # Only stop training if the baseline is reached\n",
        "        if current >= self.baseline:\n",
        "            super(BaselineEarlyStopping, self).on_epoch_end(epoch, logs)\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    mode='max',\n",
        "    restore_best_weights=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYmhi4Nb51Xy",
        "outputId": "71c338d9-1a11-4f53-8238-d61108b4bee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/999999999\n",
            "90/90 [==============================] - 8s 91ms/step - loss: 1.5548 - accuracy: 0.2709 - val_loss: 1.5225 - val_accuracy: 0.3330\n",
            "Epoch 2/999999999\n",
            "90/90 [==============================] - 8s 85ms/step - loss: 1.2438 - accuracy: 0.4905 - val_loss: 1.2496 - val_accuracy: 0.5175\n",
            "Epoch 3/999999999\n",
            "90/90 [==============================] - 8s 84ms/step - loss: 0.8781 - accuracy: 0.6635 - val_loss: 1.0264 - val_accuracy: 0.5811\n",
            "Epoch 4/999999999\n",
            "90/90 [==============================] - 8s 85ms/step - loss: 0.7248 - accuracy: 0.7256 - val_loss: 0.9618 - val_accuracy: 0.6484\n",
            "Epoch 5/999999999\n",
            "90/90 [==============================] - 8s 86ms/step - loss: 0.4674 - accuracy: 0.8242 - val_loss: 0.8840 - val_accuracy: 0.6853\n",
            "Epoch 6/999999999\n",
            "90/90 [==============================] - 8s 87ms/step - loss: 0.3383 - accuracy: 0.8758 - val_loss: 0.5404 - val_accuracy: 0.8161\n",
            "Epoch 7/999999999\n",
            "90/90 [==============================] - 8s 87ms/step - loss: 0.3237 - accuracy: 0.8933 - val_loss: 0.6857 - val_accuracy: 0.8067\n",
            "Epoch 8/999999999\n",
            "90/90 [==============================] - 8s 87ms/step - loss: 0.2028 - accuracy: 0.9309 - val_loss: 0.4952 - val_accuracy: 0.8512\n",
            "Epoch 9/999999999\n",
            "90/90 [==============================] - 8s 87ms/step - loss: 0.1835 - accuracy: 0.9358 - val_loss: 0.5771 - val_accuracy: 0.8295\n",
            "Epoch 10/999999999\n",
            "90/90 [==============================] - 8s 84ms/step - loss: 0.1528 - accuracy: 0.9491 - val_loss: 0.7735 - val_accuracy: 0.8284\n",
            "Epoch 11/999999999\n",
            "90/90 [==============================] - 8s 85ms/step - loss: 0.1146 - accuracy: 0.9632 - val_loss: 1.1554 - val_accuracy: 0.8077\n",
            "Epoch 12/999999999\n",
            "90/90 [==============================] - 8s 86ms/step - loss: 0.1100 - accuracy: 0.9614 - val_loss: 0.9214 - val_accuracy: 0.8218\n",
            "Epoch 13/999999999\n",
            "90/90 [==============================] - 8s 88ms/step - loss: 0.1138 - accuracy: 0.9646 - val_loss: 0.2980 - val_accuracy: 0.9098\n",
            "Epoch 14/999999999\n",
            "90/90 [==============================] - 8s 92ms/step - loss: 0.0599 - accuracy: 0.9786 - val_loss: 0.5893 - val_accuracy: 0.8860\n",
            "Epoch 15/999999999\n",
            "90/90 [==============================] - 14s 157ms/step - loss: 0.0909 - accuracy: 0.9677 - val_loss: 0.5121 - val_accuracy: 0.8842\n",
            "Epoch 16/999999999\n",
            "90/90 [==============================] - 15s 161ms/step - loss: 0.0743 - accuracy: 0.9737 - val_loss: 0.3444 - val_accuracy: 0.9074\n",
            "Epoch 17/999999999\n",
            "90/90 [==============================] - 15s 163ms/step - loss: 0.0516 - accuracy: 0.9849 - val_loss: 0.5051 - val_accuracy: 0.8916\n",
            "Epoch 18/999999999\n",
            "90/90 [==============================] - 15s 164ms/step - loss: 0.0608 - accuracy: 0.9811 - val_loss: 0.6271 - val_accuracy: 0.8860\n",
            "Epoch 19/999999999\n",
            "90/90 [==============================] - 15s 164ms/step - loss: 0.0457 - accuracy: 0.9870 - val_loss: 0.5533 - val_accuracy: 0.8758\n",
            "Epoch 20/999999999\n",
            "90/90 [==============================] - 15s 162ms/step - loss: 0.0480 - accuracy: 0.9853 - val_loss: 0.9396 - val_accuracy: 0.8670\n",
            "Epoch 21/999999999\n",
            "90/90 [==============================] - 14s 154ms/step - loss: 0.0754 - accuracy: 0.9761 - val_loss: 1.6751 - val_accuracy: 0.8175\n",
            "Epoch 22/999999999\n",
            "90/90 [==============================] - 15s 169ms/step - loss: 0.1271 - accuracy: 0.9593 - val_loss: 0.5047 - val_accuracy: 0.8811\n",
            "Epoch 23/999999999\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.9849Restoring model weights from the end of the best epoch: 13.\n",
            "90/90 [==============================] - 15s 165ms/step - loss: 0.0462 - accuracy: 0.9849 - val_loss: 0.7274 - val_accuracy: 0.8575\n",
            "Epoch 23: early stopping\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=999999999,\n",
        "    validation_data=validation_generator,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpAYb5U2Eui7",
        "outputId": "28cc810a-fbd3-41f2-ad8f-383cc60feb80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90/90 [==============================] - 8s 92ms/step - loss: 0.3402 - accuracy: 0.9018\n",
            "Validation accuracy: 90.18%\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(validation_generator)\n",
        "print(f'Validation accuracy: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pEUrVw6l54ox",
        "outputId": "a27aa4b4-21dd-4386-f7d8-f43b646b0c8c"
      },
      "outputs": [],
      "source": [
        "# def predict_uploaded_image(model, img_path):\n",
        "#     img = image.load_img(img_path, target_size=(150, 150))\n",
        "#     imgplot = plt.imshow(img)\n",
        "#     plt.show()\n",
        "\n",
        "#     img_array = image.img_to_array(img)\n",
        "#     img_array = np.expand_dims(img_array, axis=0) / 255.\n",
        "\n",
        "#     predictions = model.predict(img_array)\n",
        "#     classes = ['paper', 'rock', 'scissors']\n",
        "#     predicted_class = classes[np.argmax(predictions)]\n",
        "\n",
        "#     return predicted_class\n",
        "\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for fn in uploaded.keys():\n",
        "#     predicted_class = predict_uploaded_image(model, fn)\n",
        "#     print(f'Gambar {fn} diprediksi sebagai: {predicted_class}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../images/split/testing/Colin_Powell/image_3.png'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[39], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../images/split/testing/Colin_Powell/image_3.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgrayscale\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m imgplot \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mimshow(img)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\image_utils.py:422\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[0;32m    421\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[1;32m--> 422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    423\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../images/split/testing/Colin_Powell/image_3.png'"
          ]
        }
      ],
      "source": [
        "img_path = \"../images/split/testing/Colin_Powell/image_3.png\"\n",
        "\n",
        "img = image.load_img(img_path, target_size=(150, 150), color_mode='grayscale')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0) / 255.\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "classes = ['Colin', 'Donald', 'George', 'Gerhard', 'Tony']\n",
        "predicted_class = classes[np.argmax(predictions)]\n",
        "\n",
        "\n",
        "print(f'Gambar diprediksi sebagai: {predicted_class}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
