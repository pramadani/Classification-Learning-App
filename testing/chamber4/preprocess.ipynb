{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../images/10_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mimwrite(img_path, img)\n\u001b[0;32m     53\u001b[0m image_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../images/10_data\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 54\u001b[0m images, labels, classes \u001b[38;5;241m=\u001b[39m \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(images, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mlabels, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     58\u001b[0m X_train_augmented, y_train_augmented \u001b[38;5;241m=\u001b[39m oversample_with_augmentation(X_train, y_train)\n",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m, in \u001b[0;36mload_images\u001b[1;34m(image_folder, target_size)\u001b[0m\n\u001b[0;32m      2\u001b[0m images \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_name \u001b[38;5;129;01min\u001b[39;00m classes:\n\u001b[0;32m      7\u001b[0m     class_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_folder, class_name)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../images/10_data'"
     ]
    }
   ],
   "source": [
    "def load_images(image_folder, target_size=(150, 150)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    classes = os.listdir(image_folder)\n",
    "    \n",
    "    for class_name in classes:\n",
    "        class_path = os.path.join(image_folder, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            for image_name in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, image_name)\n",
    "                if image_path.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    img = cv2.resize(img, target_size)\n",
    "                    images.append(img)\n",
    "                    labels.append(class_name)\n",
    "                    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, classes\n",
    "\n",
    "def oversample_with_augmentation(X_train, y_train, img_height=150, img_width=150, sample=50):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    X_train_augmented = []\n",
    "    y_train_augmented = []\n",
    "    \n",
    "    for x, y in zip(X_train, y_train):\n",
    "        x = x.reshape((1, img_height, img_width, 1))\n",
    "        for _ in range(sample):\n",
    "            augmented = datagen.flow(x, batch_size=1)\n",
    "            X_train_augmented.append(augmented[0].reshape(img_height, img_width, 1))\n",
    "            y_train_augmented.append(y)\n",
    "\n",
    "    X_train_augmented = np.array(X_train_augmented)\n",
    "    y_train_augmented = np.array(y_train_augmented)\n",
    "    return X_train_augmented, y_train_augmented\n",
    "\n",
    "def save_images(images, labels, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for class_name in np.unique(labels):\n",
    "        class_folder = os.path.join(output_folder, class_name)\n",
    "        os.makedirs(class_folder, exist_ok=True)\n",
    "    \n",
    "    for idx, (img, label) in enumerate(zip(images, labels)):\n",
    "        img_path = os.path.join(output_folder, label, f'image_{idx}.png')\n",
    "        cv2.imwrite(img_path, img)\n",
    "\n",
    "image_folder = '../images/10_data'\n",
    "images, labels, classes = load_images(image_folder)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "X_train_augmented, y_train_augmented = oversample_with_augmentation(X_train, y_train)\n",
    "\n",
    "save_images(X_train_augmented, y_train_augmented, '../images/split/training')\n",
    "save_images(X_test, y_test, '../images/split/testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('models/landmarks.dat')\n",
    "\n",
    "def crop_face(img, detector, predictor):\n",
    "    dets = detector(img, 1)\n",
    "    if len(dets) > 0:\n",
    "        for k, d in enumerate(dets):\n",
    "            shape = predictor(img, d)\n",
    "            x1, y1, x2, y2 = d.left(), d.top(), d.right(), d.bottom()\n",
    "            return img[y1:y2, x1:x2]\n",
    "    return img\n",
    "\n",
    "def load_images(image_folder, target_size=(150, 150)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    classes = os.listdir(image_folder)\n",
    "    \n",
    "    for class_name in classes:\n",
    "        class_path = os.path.join(image_folder, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            for image_name in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, image_name)\n",
    "                if image_path.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    resized_img = cv2.resize(img, target_size)\n",
    "                    images.append(resized_img)\n",
    "                    labels.append(class_name)\n",
    "                    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, classes\n",
    "\n",
    "def oversample_with_augmentation(X_train, y_train, img_height=150, img_width=150, sample=100):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    X_train_augmented = []\n",
    "    y_train_augmented = []\n",
    "    \n",
    "    for x, y in zip(X_train, y_train):\n",
    "        x = x.reshape((1, img_height, img_width, 1))\n",
    "        for _ in range(sample):\n",
    "            augmented = datagen.flow(x, batch_size=1)\n",
    "            X_train_augmented.append(augmented[0].reshape(img_height, img_width, 1))\n",
    "            y_train_augmented.append(y)\n",
    "\n",
    "    X_train_augmented = np.array(X_train_augmented, dtype=np.uint8)\n",
    "    y_train_augmented = np.array(y_train_augmented)\n",
    "    return X_train_augmented, y_train_augmented\n",
    "\n",
    "def crop_augmented_images(X, detector, predictor, target_size=(150, 150)):\n",
    "    X_cropped = []\n",
    "    for img in X:\n",
    "        img_cropped = crop_face(img.squeeze(), detector, predictor)\n",
    "        if img_cropped.size != 0:\n",
    "            img_resized = cv2.resize(img_cropped, target_size)\n",
    "            X_cropped.append(img_resized.reshape(target_size[0], target_size[1], 1))\n",
    "    return np.array(X_cropped)\n",
    "\n",
    "def save_images(images, labels, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for class_name in np.unique(labels):\n",
    "        class_folder = os.path.join(output_folder, class_name)\n",
    "        os.makedirs(class_folder, exist_ok=True)\n",
    "    \n",
    "    for idx, (img, label) in enumerate(zip(images, labels)):\n",
    "        img_path = os.path.join(output_folder, label, f'image_{idx}.png')\n",
    "        cv2.imwrite(img_path, img)\n",
    "\n",
    "image_folder = 'images/10_data'\n",
    "images, labels, classes = load_images(image_folder)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "X_train_augmented, y_train_augmented = oversample_with_augmentation(X_train, y_train)\n",
    "\n",
    "# X_train_cropped = crop_augmented_images(X_train_augmented, detector, predictor)\n",
    "# X_test_cropped = crop_augmented_images(X_test, detector, predictor)\n",
    "\n",
    "save_images(X_train_augmented, y_train_augmented, 'images/split/training')\n",
    "save_images(X_test, y_test, 'images/split/testing')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
